# ğŸ¤– AI Service Boilerplate 2025 â€” by Wali

![CI](https://img.shields.io/github/actions/workflow/status/AdaaJr/ai-service-boilerplate/ci.yml?branch=dev&label=CI)
[![Docs](https://img.shields.io/badge/Docs-GitHub%20Pages-informational)](https://adaajr.github.io/ai-service-boilerplate/)

Ce projet est une **API IA prÃªte pour la production**, que jâ€™ai conÃ§ue comme un **point de dÃ©part** pour tout projet autour du **traitement du langage** (chatbots, assistants, embeddingsâ€¦). Elle reprend les standards **OpenAI-like** (`/v1/chat/completions`, `/v1/embeddings`) pour Ãªtre **compatible avec les clients existants** (langchain, openai-python, etc.).

---

## ğŸ“¸ AperÃ§u (diagrammes)

### Architecture globale
![Architecture globale](diagrams/architecture.png)

### Composants internes
![Composants internes](diagrams/internal-components.png)

### Flux dâ€™une requÃªte chat
![Flux request](diagrams/request-flow.png)

---

## ğŸ” Ã€ quoi Ã§a sert ?

- ğŸš€ Fournir une **API IA prÃªte Ã  lâ€™emploi**, utilisable en local, sur serveur ou en cloud.
- ğŸ”„ **Switcher facilement de backend** modÃ¨le (Hugging Face, Ollama, vLLM bientÃ´t) sans changer vos clients.
- ğŸ” Offrir une **base sÃ©curisÃ©e** (auth API keys, CORS, rate limiting) pour dÃ©ployer en interne ou en SaaS.
- ğŸ§° Servir de **boilerplate pÃ©dagogique** pour comprendre un service IA moderne (API, sÃ©curitÃ©, CI).

### Exemples dâ€™usages
- **Assistant interne** sur documents (embeddings + retrieval).
- **Recherche sÃ©mantique** (Pinecone, Weaviate, PGVectorâ€¦).
- **Chatbot produit / support** (site web, Slack/Teams).
- **API perso** compatible outils OpenAI.

---

## âœ¨ FonctionnalitÃ©s

- Endpoints : `GET /healthz`, `POST /v1/chat/completions`, `POST /v1/embeddings`.
- Backends : **Hugging Face (CPU)**, **Ollama (local)**, **Mock** (tests) â€” vLLM en extension.
- SÃ©curitÃ© : **API keys** (`Authorization: Bearer ...`), **CORS**, rate limit simple.
- ObservabilitÃ© : Logs **JSON**, **OpenTelemetry** (traces).
- QualitÃ© : **ruff**, **mypy**, **pytest**.
- Supply chain : **SBOM** (Syft), scans **Trivy** (image) et **gitleaks** (secrets).
- Docker : image non-root, prÃªte pour **ECR/ECS**.

---

## ğŸš€ DÃ©marrer en local

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
```

Test rapide :
```bash
curl -s http://localhost:8000/healthz
curl -s http://localhost:8000/v1/chat/completions   -H 'Content-Type: application/json'   -H 'Authorization: Bearer devkey'   -d '{"model":"hf:distilbert-base-uncased","messages":[{"role":"user","content":"Hello"}]}'
```

Docker :
```bash
docker build -t wali/ai-service:dev .
docker run -p 8000:8000 -e API_KEYS='["devkey"]' wali/ai-service:dev
```

---

## ğŸ” Configuration (env)

- `API_KEYS` : liste JSON de clÃ©s API autorisÃ©es (ex: `["devkey"]`)
- `ALLOW_ORIGINS` : CORS (ex: `["*"]` pour dev, restreindre en prod)
- `MODEL_BACKEND` : `hf`, `ollama` ou `mock`
- `HF_MODEL_ID` : ex: `distilbert-base-uncased`
- `OLLAMA_HOST` : ex: `http://localhost:11434`

---

## ğŸ§ª QualitÃ© & CI

- **CI** : lint (ruff), mypy, tests (pytest), build Docker, SBOM (syft), scans (gitleaks, trivy).
- Badge CI : en haut du README (branche `dev`).

---

## ğŸ—ºï¸ Roadmap

- Backend **vLLM**, batching, file uploads, cache Redis, monitoring Prometheus, token limits, persistance S3.

---

âœï¸ **Auteur** : Wali Diabi â€” 2025
